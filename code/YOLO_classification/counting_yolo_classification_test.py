# -*- coding: utf-8 -*-
"""ã€ŒYOLO_SEALIONã€çš„ç°¡å–®ç‰ˆ

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12RPfyrxKb9BWD6cwYZKOmbxOrMqcGuip
"""

!pip install ultralytics
!pip install pandas
!pip install torch
!pip install tqdm

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import torch
from ultralytics import YOLO
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict
import logging
import matplotlib.pyplot as plt
import zipfile
# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import torch
from ultralytics import YOLO
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict
import logging
import matplotlib.pyplot as plt
import zipfile
# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

#%%
# æµ·ç…é¡åˆ¥å®šç¾© (5å€‹é¡åˆ¥)
SEALION_CLASSES = {
    0: 'class_0_Adult Males',
    1: 'class_1_Subadult Males',
    2: 'class_2_Adult Females',
    3: 'class_3_Juveniles',
    4: 'class_4_Pups'
}

# è¨­å®šæª”æ¡ˆè·¯å¾‘
model_path = '/content/drive/MyDrive/DL_HW/final/yolo11x-cls_sealion_60.pt'  # æ‚¨çš„æ¨¡å‹è·¯å¾‘

# æ¸¬è©¦è³‡æ–™é¸é … - é¸æ“‡å…¶ä¸­ä¸€ç¨®
# é¸é …1: ç›´æ¥ä½¿ç”¨è³‡æ–™å¤¾
#image_folder = '/content/drive/MyDrive/preprocessed_images'   # 100x100åœ–ç‰‡è³‡æ–™å¤¾

# é¸é …2: ä½¿ç”¨ZIPæª”æ¡ˆ (å¦‚æœæœ‰çš„è©±æœƒè‡ªå‹•è§£å£“ç¸®)
zip_file_path = '/content/drive/MyDrive/DL_HW/final/Test_Sealion_60.zip'      # ZIPå£“ç¸®æª”è·¯å¾‘
extract_folder = '/content/Test_Sealion_60'                 # è§£å£“ç¸®ç›®æ¨™è³‡æ–™å¤¾

output_csv = '/content/drive/MyDrive/DL_HW/final/sealion_60_count_results.csv'           # è¼¸å‡ºæª”æ¡ˆ

# è¼‰å…¥æ¨¡å‹
if os.path.exists(model_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = YOLO(model_path)
    print(f"âœ… æ¨¡å‹å·²è¼‰å…¥: {model_path}")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
else:
    print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
    print("è«‹ç¢ºä¿æ¨¡å‹æª”æ¡ˆåœ¨ Google Drive ä¸­")

def extract_zip_file(zip_path, extract_to):
    """è§£å£“ç¸®ZIPæª”æ¡ˆ"""

    if not os.path.exists(zip_path):
        print(f"âŒ ZIPæª”æ¡ˆä¸å­˜åœ¨: {zip_path}")
        return False

    try:
        # å»ºç«‹è§£å£“ç¸®ç›®æ¨™è³‡æ–™å¤¾
        os.makedirs(extract_to, exist_ok=True)

        print(f"ğŸ“¦ é–‹å§‹è§£å£“ç¸®: {zip_path}")

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # ç²å–ZIPæª”æ¡ˆè³‡è¨Š
            file_list = zip_ref.namelist()
            total_files = len(file_list)

            print(f"ğŸ“ ZIPæª”æ¡ˆåŒ…å« {total_files} å€‹æª”æ¡ˆ")

            # è§£å£“ç¸®æ‰€æœ‰æª”æ¡ˆ
            zip_ref.extractall(extract_to)

            # çµ±è¨ˆåœ–ç‰‡æª”æ¡ˆ
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
            image_count = 0

            for file_name in file_list:
                if any(file_name.lower().endswith(ext) for ext in image_extensions):
                    image_count += 1

            print(f"âœ… è§£å£“ç¸®å®Œæˆï¼")
            print(f"ğŸ“· æ‰¾åˆ° {image_count} å¼µåœ–ç‰‡æª”æ¡ˆ")
            print(f"ğŸ“ è§£å£“ç¸®ä½ç½®: {extract_to}")

            return True

    except Exception as e:
        print(f"âŒ è§£å£“ç¸®å¤±æ•—: {e}")
        return False

def determine_image_source():
    """æ±ºå®šä½¿ç”¨å“ªç¨®åœ–ç‰‡ä¾†æº"""

    # æª¢æŸ¥æ˜¯å¦æœ‰ZIPæª”æ¡ˆ
    if os.path.exists(zip_file_path):
        print(f"ğŸ” ç™¼ç¾ZIPæª”æ¡ˆ: {zip_file_path}")

        # æª¢æŸ¥æ˜¯å¦å·²ç¶“è§£å£“ç¸®é
        if os.path.exists(extract_folder) and os.listdir(extract_folder):
            print(f"ğŸ“ è§£å£“ç¸®è³‡æ–™å¤¾å·²å­˜åœ¨ä¸”éç©º: {extract_folder}")

            # è©¢å•æ˜¯å¦é‡æ–°è§£å£“ç¸®
            print("é¸é …:")
            print("1. ä½¿ç”¨ç¾æœ‰è§£å£“ç¸®è³‡æ–™å¤¾")
            print("2. é‡æ–°è§£å£“ç¸®ZIPæª”æ¡ˆ")

            # åœ¨Colabä¸­ï¼Œæˆ‘å€‘é è¨­ä½¿ç”¨ç¾æœ‰è³‡æ–™å¤¾ï¼Œé™¤éè³‡æ–™å¤¾ç‚ºç©º
            if len(os.listdir(extract_folder)) > 0:
                print("â¡ï¸ ä½¿ç”¨ç¾æœ‰è§£å£“ç¸®è³‡æ–™å¤¾")
                return extract_folder
            else:
                print("â¡ï¸ è³‡æ–™å¤¾ç‚ºç©ºï¼Œé‡æ–°è§£å£“ç¸®")

        # è§£å£“ç¸®ZIPæª”æ¡ˆ
        if extract_zip_file(zip_file_path, extract_folder):
            return extract_folder
        else:
            print("âš ï¸ ZIPè§£å£“ç¸®å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨åŸå§‹è³‡æ–™å¤¾")

    # æª¢æŸ¥åŸå§‹è³‡æ–™å¤¾
    if os.path.exists(image_folder):
        print(f"ğŸ“ ä½¿ç”¨åŸå§‹è³‡æ–™å¤¾: {image_folder}")
        return image_folder
    else:
        print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡è³‡æ–™å¤¾: {image_folder}")
        return None

def extract_image_id(filename):
    """
    å¾æª”åæå–åŸåœ–ç·¨è™Ÿ

    Args:
        filename: æª”æ¡ˆåç¨±ï¼Œæ ¼å¼: {åŸåœ–ç·¨è™Ÿ}_å‰©é¤˜å¾Œç¶´.jpg

    Returns:
        åŸåœ–ç·¨è™Ÿ (å­—ä¸²)
    """
    # ç§»é™¤å‰¯æª”å
    name_without_ext = Path(filename).stem

    # ä»¥ç¬¬ä¸€å€‹åº•ç·šåˆ†å‰²ï¼Œå–ç¬¬ä¸€éƒ¨åˆ†ä½œç‚ºåŸåœ–ç·¨è™Ÿ
    image_id = name_without_ext.split('_')[0]

    return image_id

def collect_image_files(folder_path):
    """æ”¶é›†è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ (åŒ…å«å­è³‡æ–™å¤¾)"""

    folder = Path(folder_path)

    # æ”¯æ´çš„åœ–ç‰‡å‰¯æª”å
    supported_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}

    # æ”¶é›†æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ (åŒ…å«å­è³‡æ–™å¤¾)
    image_files = []

    # éæ­¸æœå°‹æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
    for ext in supported_extensions:
        image_files.extend(folder.rglob(f'*{ext}'))
        image_files.extend(folder.rglob(f'*{ext.upper()}'))

    # ç§»é™¤é‡è¤‡æª”æ¡ˆ
    image_files = list(set(image_files))

    return image_files

def predict_and_accumulate(model, image_files):
    """é æ¸¬æ‰€æœ‰åœ–ç‰‡ä¸¦ç´¯ç©çµæœ"""

    # ç”¨æ–¼ç´¯ç©æ¯å€‹åŸåœ–çš„åˆ†é¡çµæœ
    image_results = defaultdict(lambda: {class_name.replace('class_', ''): 0
                                       for class_name in SEALION_CLASSES.values()})
    image_confidence = defaultdict(list)

    print(f"é–‹å§‹é æ¸¬ {len(image_files)} å¼µåœ–ç‰‡...")

    # æº–å‚™åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
    image_paths = [str(img_path) for img_path in image_files]

    # æ‰¹é‡é æ¸¬ (æ›´é«˜æ•ˆ)
    try:
        # æ”¹ç”¨ stream=Trueï¼Œé¿å…è¨˜æ†¶é«”çˆ†æ‰
      from more_itertools import chunked

      BATCH_SIZE = 256
      for batch in tqdm(chunked(image_files, BATCH_SIZE), total=len(image_files) // BATCH_SIZE):
          batch_paths = [str(p) for p in batch]
          results = model(batch_paths, stream=True, verbose=False)
          for img_path, result in zip(batch, results):
              # å–®å¼µè™•ç†

            # æå–åŸåœ–ç·¨è™Ÿ
            image_id = extract_image_id(img_path.name)

            # è™•ç†é æ¸¬çµæœ
            if hasattr(result, 'probs') and result.probs is not None:
                class_id = result.probs.top1
                confidence = result.probs.top1conf.item()
                class_name = SEALION_CLASSES.get(class_id, 'æœªçŸ¥')

                # ç°¡åŒ–é¡åˆ¥åç¨± (ç§»é™¤ class_ å‰ç¶´)
                simplified_class = class_name.replace('class_', '')

                # ç´¯åŠ åˆ°å°æ‡‰åŸåœ–
                image_results[image_id][simplified_class] += 1
                image_confidence[image_id].append(confidence)

            else:
                logger.warning(f"é æ¸¬å¤±æ•—: {img_path.name}")

    except Exception as e:
        print(f"âš ï¸ æ‰¹é‡é æ¸¬å¤±æ•—ï¼Œæ”¹ç”¨å–®å¼µé æ¸¬: {e}")

        # å¦‚æœæ‰¹é‡é æ¸¬å¤±æ•—ï¼Œæ”¹ç”¨å–®å¼µé æ¸¬
        for img_path in tqdm(image_files, desc="å–®å¼µé æ¸¬é€²åº¦"):
            try:
                result = model(str(img_path), verbose=False)[0]

                # æå–åŸåœ–ç·¨è™Ÿ
                image_id = extract_image_id(img_path.name)

                # è™•ç†é æ¸¬çµæœ
                if hasattr(result, 'probs') and result.probs is not None:
                    class_id = result.probs.top1
                    confidence = result.probs.top1conf.item()
                    class_name = SEALION_CLASSES.get(class_id, 'æœªçŸ¥')

                    # ç°¡åŒ–é¡åˆ¥åç¨±
                    simplified_class = class_name.replace('class_', '')

                    # ç´¯åŠ åˆ°å°æ‡‰åŸåœ–
                    image_results[image_id][simplified_class] += 1
                    image_confidence[image_id].append(confidence)

                else:
                    logger.warning(f"é æ¸¬å¤±æ•—: {img_path.name}")

            except Exception as e2:
                logger.error(f"é æ¸¬ {img_path.name} æ™‚å‡ºéŒ¯: {e2}")

    return image_results, image_confidence

actual_image_folder = determine_image_source()

if actual_image_folder:
    image_files = collect_image_files(actual_image_folder)
    print(f"âœ… æœ€çµ‚ä½¿ç”¨è³‡æ–™å¤¾: {actual_image_folder}")
    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡")

    # é¡¯ç¤ºå‰10å€‹æª”æ¡ˆç¯„ä¾‹
    print(f"\nå‰10å€‹æª”æ¡ˆç¯„ä¾‹:")
    for i, img_file in enumerate(image_files[:10]):
        image_id = extract_image_id(img_file.name)
        # é¡¯ç¤ºç›¸å°è·¯å¾‘
        rel_path = img_file.relative_to(Path(actual_image_folder))
        print(f"  {rel_path} -> åŸåœ–ç·¨è™Ÿ: {image_id}")

    if len(image_files) > 10:
        print(f"  ... é‚„æœ‰ {len(image_files) - 10} å¼µåœ–ç‰‡")

    # æª¢æŸ¥æª”åæ ¼å¼
    print(f"\næª”åæ ¼å¼æª¢æŸ¥:")
    valid_format_count = 0
    for img_file in image_files[:20]:  # æª¢æŸ¥å‰20å€‹
        if '_' in img_file.stem:
            valid_format_count += 1

    format_ratio = valid_format_count / min(20, len(image_files))
    print(f"  ç¬¦åˆæ ¼å¼ ({image_id}_xxx) çš„æª”æ¡ˆæ¯”ä¾‹: {format_ratio:.1%}")

    if format_ratio < 0.8:
        print("  âš ï¸ è­¦å‘Š: å¤§éƒ¨åˆ†æª”æ¡ˆå¯èƒ½ä¸ç¬¦åˆé æœŸæ ¼å¼")

else:
    print("âŒ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„åœ–ç‰‡ä¾†æº")
    print("è«‹ç¢ºä¿:")
    print("  1. ZIPæª”æ¡ˆè·¯å¾‘æ­£ç¢º")
    print("  2. æˆ–åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘æ­£ç¢º")
    print("  3. æª”æ¡ˆå·²ä¸Šå‚³åˆ°Google Drive")

if 'image_files' in locals() and len(image_files) > 0 and 'model' in locals():
    # åŸ·è¡Œé æ¸¬
    image_results, image_confidence = predict_and_accumulate(model, image_files)

    print(f"âœ… é æ¸¬å®Œæˆï¼")
    print(f"ğŸ“Š è™•ç†äº† {len(image_results)} å¼µåŸåœ–")
    print(f"ğŸ“· ç¸½å…±é æ¸¬äº† {len(image_files)} å¼µå°åœ–ç‰‡")

    # é¡¯ç¤ºè™•ç†æ•ˆç‡
    if len(image_results) > 0:
        avg_images_per_original = len(image_files) / len(image_results)
        print(f"ğŸ“ˆ å¹³å‡æ¯å¼µåŸåœ–åŒ…å« {avg_images_per_original:.1f} å¼µå°åœ–ç‰‡")
else:
    if 'model' not in locals():
        print("âŒ æ¨¡å‹æœªè¼‰å…¥ï¼Œç„¡æ³•åŸ·è¡Œé æ¸¬")
    else:
        print("âŒ æ²’æœ‰åœ–ç‰‡å¯é æ¸¬")

if 'image_results' in locals() and image_results:

    # å»ºç«‹çµæœæ•¸æ“š
    result_data = []

    for image_id in image_results:
        row = {'image_id': image_id}

        # æ·»åŠ å„é¡åˆ¥æ•¸é‡
        total_sealions = 0
        for class_name in ['0_Adult Males', '1_Subadult Males', '2_Adult Females', '3_Juveniles', '4_Pups']:
            count = image_results[image_id][class_name]
            row[class_name] = count
            total_sealions += count

        # ç¸½è¨ˆå’Œå¹³å‡ä¿¡å¿ƒåº¦
        row['total_sealions'] = total_sealions

        if image_confidence[image_id]:
            row['avg_confidence'] = sum(image_confidence[image_id]) / len(image_confidence[image_id])
        else:
            row['avg_confidence'] = 0.0

        result_data.append(row)

    # å»ºç«‹ DataFrame ä¸¦æ’åº
    results_df = pd.DataFrame(result_data)
    results_df = results_df.sort_values('image_id')

    print(f"âœ… çµæœ DataFrame å»ºç«‹å®Œæˆï¼")
    print(f"ğŸ“Š åŒ…å« {len(results_df)} å¼µåŸåœ–çš„çµ±è¨ˆçµæœ")

else:
    print("âŒ æ²’æœ‰é æ¸¬çµæœå¯è™•ç†")

if 'results_df' in locals() and not results_df.empty:

    print(f"=== é æ¸¬çµæœæ‘˜è¦ ===")
    print(f"è™•ç†åŸåœ–æ•¸é‡: {len(results_df)}")
    print(f"ç¸½æµ·ç…æ•¸é‡: {results_df['total_sealions'].sum()}")
    print(f"å¹³å‡æ¯å¼µåŸåœ–æµ·ç…æ•¸: {results_df['total_sealions'].mean():.2f}")
    print(f"å¹³å‡ä¿¡å¿ƒåº¦: {results_df['avg_confidence'].mean():.4f}")

    # å„é¡åˆ¥ç¸½æ•¸çµ±è¨ˆ
    class_columns = ['0_Adult Males', '1_Subadult Males', '2_Adult Females', '3_Juveniles', '4_Pups']
    total_all = results_df['total_sealions'].sum()

    print(f"\nå„é¡åˆ¥çµ±è¨ˆ:")
    for col in class_columns:
        total = results_df[col].sum()
        percentage = (total / total_all * 100) if total_all > 0 else 0
        print(f"  {col}: {total} ({percentage:.1f}%)")

    # é¡¯ç¤ºå‰10ç­†çµæœ
    print(f"\nå‰10ç­†çµæœ:")
    print(results_df.head(10).to_string(index=False))

else:
    print("âŒ æ²’æœ‰çµæœå¯é¡¯ç¤º")

if 'results_df' in locals() and not results_df.empty:

    # Prepare class columns (keep in Chinese for data processing)
    class_columns = ['0_Adult Males', '1_Subadult Males', '2_Adult Females', '3_Juveniles', '4_Pups']

    # Mapping for display in English
    class_label_map = {
        '0_æˆå¹´é›„æ€§': '0_Adult Male',
        '1_äºæˆå¹´é›„æ€§': '1_Subadult Male',
        '2_æˆå¹´é›Œæ€§': '2_Adult Female',
        '3_å¹¼ç¸': '3_Juvenile',
        '4_å¹¼å´½': '4_Pup'
    }

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. Total count distribution per class
    class_totals = results_df[class_columns].sum()
    labels_pie = [class_label_map.get(c, c) for c in class_totals.index]
    axes[0, 0].pie(class_totals.values, labels=labels_pie, autopct='%1.1f%%')
    axes[0, 0].set_title('Total Distribution per Class')

    # 2. Sealion count per original image
    axes[0, 1].hist(results_df['total_sealions'], bins=20, alpha=0.7, edgecolor='black')
    axes[0, 1].set_title('Number of Sealions per Image')
    axes[0, 1].set_xlabel('Number of Sealions')
    axes[0, 1].set_ylabel('Number of Images')

    # 3. Average confidence distribution
    axes[1, 0].hist(results_df['avg_confidence'], bins=20, alpha=0.7, edgecolor='black')
    axes[1, 0].set_title('Average Confidence Distribution')
    axes[1, 0].set_xlabel('Average Confidence')
    axes[1, 0].set_ylabel('Number of Images')

    # 4. Presence frequency of each class in images
    class_presence = (results_df[class_columns] > 0).sum()
    labels_bar = [class_label_map.get(c, c) for c in class_presence.index]
    axes[1, 1].bar(labels_bar, class_presence.values)
    axes[1, 1].set_title('Class Presence Frequency in Images')
    axes[1, 1].set_xlabel('Class')
    axes[1, 1].set_ylabel('Number of Images with Class Present')
    axes[1, 1].tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.savefig('/content/sealion_statistics.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("ğŸ“Š Statistics chart saved to: /content/sealion_statistics.png")

if 'results_df' in locals() and not results_df.empty:

    # å„²å­˜ä¸»è¦çµæœ
    results_df.to_csv(output_csv, index=False)
    print(f"âœ… çµæœå·²å„²å­˜è‡³: {output_csv}")

    # æª¢æŸ¥æª”æ¡ˆå¤§å°
    file_size = os.path.getsize(output_csv) / 1024  # KB
    print(f"ğŸ“ æª”æ¡ˆå¤§å°: {file_size:.2f} KB")

    # é¡¯ç¤ºCSVå…§å®¹é è¦½
    print(f"\nCSVæª”æ¡ˆé è¦½:")
    print(results_df.head().to_string(index=False))

else:
    print("âŒ æ²’æœ‰çµæœå¯å„²å­˜")

from google.colab import files

# ä¸‹è¼‰ä¸»è¦çµæœæª”æ¡ˆ
if os.path.exists(output_csv):
    files.download(output_csv)
    print(f"â¬‡ï¸ å·²ä¸‹è¼‰çµæœæª”æ¡ˆ: {output_csv}")

# ä¸‹è¼‰çµ±è¨ˆåœ–è¡¨
chart_file = '/content/sealion_statistics.png'
if os.path.exists(chart_file):
    files.download(chart_file)
    print(f"â¬‡ï¸ å·²ä¸‹è¼‰çµ±è¨ˆåœ–è¡¨: {chart_file}")

if 'results_df' in locals() and not results_df.empty:

    print("=== é€²éšåˆ†æ ===")

    # 1. æ‰¾å‡ºæµ·ç…æœ€å¤šçš„åŸåœ–
    max_sealions = results_df.loc[results_df['total_sealions'].idxmax()]
    print(f"\næµ·ç…æœ€å¤šçš„åŸåœ–:")
    print(f"  åŸåœ–ç·¨è™Ÿ: {max_sealions['image_id']}")
    print(f"  ç¸½æµ·ç…æ•¸: {max_sealions['total_sealions']}")
    print(f"  ä¿¡å¿ƒåº¦: {max_sealions['avg_confidence']:.4f}")

    # 2. æ‰¾å‡ºå„é¡åˆ¥å‡ºç¾æœ€å¤šçš„åŸåœ–
    class_columns = ['0_Adult Males', '1_Subadult Males', '2_Adult Females', '3_Juveniles', '4_Pups']
    print(f"\nå„é¡åˆ¥æœ€å¤šçš„åŸåœ–:")
    for col in class_columns:
        if results_df[col].max() > 0:
            max_row = results_df.loc[results_df[col].idxmax()]
            print(f"  {col}: åŸåœ– {max_row['image_id']} ({max_row[col]} éš»)")

    # 3. çµ±è¨ˆåˆ†å¸ƒ
    print(f"\nåˆ†å¸ƒçµ±è¨ˆ:")
    print(f"  æœ‰æµ·ç…çš„åŸåœ–: {(results_df['total_sealions'] > 0).sum()}")
    print(f"  ç„¡æµ·ç…çš„åŸåœ–: {(results_df['total_sealions'] == 0).sum()}")
    print(f"  æœ€å¤§æµ·ç…æ•¸: {results_df['total_sealions'].max()}")
    print(f"  ä¿¡å¿ƒåº¦ä¸­ä½æ•¸: {results_df['avg_confidence'].median():.4f}")

print("\nğŸ‰ ç°¡åŒ–æµ·ç…åˆ†é¡é æ¸¬å®Œæˆï¼")

if 'image_files' in locals() and len(image_files) > 0:
    test_images = image_files[:2000]  # æ¸¬è©¦å‰20å¼µ
    print(f"æ¸¬è©¦ {len(test_images)} å¼µåœ–ç‰‡...")

    test_class_stats = {}

    for img_path in test_images:
        try:
            result = model(str(img_path), verbose=False)[0]

            if hasattr(result, 'probs') and result.probs is not None:
                class_id = result.probs.top1
                confidence = result.probs.top1conf.item()
                class_name = SEALION_CLASSES.get(class_id, f'æœªçŸ¥é¡åˆ¥_{class_id}')

                if class_id not in test_class_stats:
                    test_class_stats[class_id] = 0
                test_class_stats[class_id] += 1

                print(f"   {img_path.name}: é¡åˆ¥ {class_id} ({class_name}), ä¿¡å¿ƒåº¦: {confidence:.3f}")
            else:
                print(f"   {img_path.name}: é æ¸¬å¤±æ•—")

        except Exception as e:
            print(f"   {img_path.name}: éŒ¯èª¤ - {e}")

    print(f"\nå¿«é€Ÿæ¸¬è©¦é¡åˆ¥çµ±è¨ˆ:")
    for class_id, count in sorted(test_class_stats.items()):
        class_name = SEALION_CLASSES.get(class_id, f'æœªçŸ¥é¡åˆ¥_{class_id}')
        print(f"   é¡åˆ¥ {class_id} ({class_name}): {count} å¼µ")

    # æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„é¡åˆ¥
    expected_classes = set(range(5))  # 0, 1, 2, 3, 4
    found_classes = set(test_class_stats.keys())
    missing_classes = expected_classes - found_classes

    if missing_classes:
        print(f"\nâš ï¸ è­¦å‘Šï¼šåœ¨æ¸¬è©¦æ¨£æœ¬ä¸­æ²’æœ‰ç™¼ç¾ä»¥ä¸‹é¡åˆ¥: {missing_classes}")
        print("é€™å¯èƒ½è¡¨ç¤ºï¼š")
        print("1. æ¨¡å‹æ²’æœ‰é æ¸¬å‡ºé€™äº›é¡åˆ¥")
        print("2. æ¸¬è©¦æ¨£æœ¬ä¸­ç¢ºå¯¦æ²’æœ‰é€™äº›é¡åˆ¥çš„åœ–ç‰‡")
        print("3. æ¨¡å‹çš„é¡åˆ¥æ•¸é‡èˆ‡é æœŸä¸ç¬¦")
    else:
        print(f"\nâœ… æ‰€æœ‰5å€‹é¡åˆ¥éƒ½åœ¨æ¸¬è©¦æ¨£æœ¬ä¸­è¢«ç™¼ç¾")
else:
    print("âŒ æ²’æœ‰åœ–ç‰‡å¯æ¸¬è©¦")